{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:13:23.704000Z",
     "start_time": "2017-12-18T15:13:20.959870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import helpers.GenerateVectors as GV\n",
    "import ast\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:13:28.023956Z",
     "start_time": "2017-12-18T15:13:28.009281Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:13:40.733312Z",
     "start_time": "2017-12-18T15:13:38.919456Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_to_filename = pickle.load(open(\"data/models/idx_to_filename.pkl\", 'rb'))\n",
    "idx_to_metadata = pickle.load(open(\"data/models/idx_to_metadata.pkl\", 'rb'))\n",
    "allvocab_to_idx = pickle.load(open(\"data/models/allvocab_to_idx.pkl\", 'rb'))\n",
    "allvocab = allvocab_to_idx.keys()\n",
    "wvvocab_to_idx = pickle.load(open(\"data/models/wvvocab_to_idx.pkl\", 'rb'))\n",
    "wvvocab = wvvocab_to_idx.keys()\n",
    "counts = pickle.load(open(\"data/models/word_counts.pkl\", 'rb'))\n",
    "embedding_matrix = pickle.load(open(\"data/models/embedding_matrix.pkl\", 'rb'))\n",
    "sentence_vectors = pickle.load(open(\"data/models/sentence_vectors.pkl\", 'rb'))\n",
    "sentence_words = pickle.load(open(\"data/models/sentence_words.pkl\", 'rb'))\n",
    "sentence_words_idx = pickle.load(\n",
    "    open(\"data/models/sentence_words_idx.pkl\", 'rb'))\n",
    "english_words = pickle.load(open(\"data/models/english_words.pkl\", 'rb')).keys()\n",
    "french_words = pickle.load(open(\"data/models/french_words.pkl\", 'rb')).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:13:45.266399Z",
     "start_time": "2017-12-18T15:13:45.259753Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "NUM_ANSWERS = 10\n",
    "TEXT_DATA_DIR = 'data/texts-pkls/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:14:40.818210Z",
     "start_time": "2017-12-18T15:14:40.383711Z"
    },
    "code_folding": [
     1,
     10,
     21,
     69
    ]
   },
   "outputs": [],
   "source": [
    "def query_to_vector(text):\n",
    "    global wvvocab_to_idx, wvvocab\n",
    "    global counts, embedding_matrix\n",
    "\n",
    "    sentence_idx = [wvvocab_to_idx[word]\n",
    "                    for word in GV.cleanpassage(text).split() if word in wvvocab]\n",
    "    return(GV.sentence_to_vec_idx([sentence_idx], counts, embedding_matrix, from_persisted=True))\n",
    "\n",
    "def distangle(x,y):\n",
    "    a = np.empty((len(x),len(y)))\n",
    "    for i,xi in enumerate(x):\n",
    "        for j,yj in enumerate(y):\n",
    "            if np.linalg.norm(xi) == 0 or np.linalg.norm(yj) == 0:\n",
    "                a[i,j] = -1\n",
    "            else:\n",
    "                a[i,j] = np.dot(xi,yj)\n",
    "    return(-a)\n",
    "\n",
    "def retrieve_closest_passages(query, from_pdfs=None, idx_true=None):\n",
    "    \"retourne la liste des num_passages les plus proches de la query parmis les sentence_vectors.\"\n",
    "    # from_pdf: liste de pdf. Seulement parmis les vectors du code pdf fourni (format idx_to_filename).\n",
    "    # idx_true: Passage recherché (format int idx de la liste pages_list), si fourni, retourne aussi la position dans les queries de la vraie réponse dans la variable position_true.\n",
    "    global sentence_vectors, sentence_words, sentence_words_idx\n",
    "    global idx_to_filename,idx_to_metadata, allvocab_to_idx, allvocab, wvvocab_to_idx, wvvocab\n",
    "    global counts, embedding_matrix\n",
    "    global position_true\n",
    "\n",
    "    query_idx = [allvocab_to_idx[word]\n",
    "                 for word in GV.cleanpassage(query).split() if word in allvocab]\n",
    "\n",
    "    indexes = []\n",
    "    filtered_vectors = []\n",
    "\n",
    "\n",
    "    if from_pdfs is not None: pdf_list = set(from_pdfs)\n",
    "    else: pdf_list = set(idx_to_filename.values())\n",
    "\n",
    "\n",
    "    for i, v in enumerate(sentence_vectors):\n",
    "        if idx_to_filename[int(idx_to_metadata[i].split(\"-\")[0])] in pdf_list:\n",
    "            grepsome = 0\n",
    "            for word_idx in query_idx:\n",
    "                if word_idx in sentence_words[sentence_words_idx[i]:sentence_words_idx[i + 1]]:\n",
    "                    grepsome += 1\n",
    "            filtered_vectors.append(v)\n",
    "            indexes.append([i, len(indexes), grepsome])\n",
    "\n",
    "\n",
    "    if len(filtered_vectors) == 0:\n",
    "        print('ERREUR: pdf(s) introuvable:', ' '.join(from_pdfs))\n",
    "        return([])\n",
    "\n",
    "    vector = query_to_vector(query)\n",
    "    distances = distangle([vector], filtered_vectors)[0]\n",
    "\n",
    "    closest_indexes = sorted(indexes, key=lambda k: (-k[2], distances[k[1]]))\n",
    "\n",
    "    answers = list(map(list, zip(*closest_indexes)))[0]\n",
    "    if idx_true is not None:\n",
    "        position_true = list(\n",
    "            map(list, zip(*closest_indexes)))[0].index(idx_true) + 1\n",
    "\n",
    "    return(answers)\n",
    "\n",
    "def get_closest_passages(answers, num_answers=NUM_ANSWERS):\n",
    "\n",
    "    #answer = {\n",
    "    #     \"raw_passage\": raw_passages[closest_indexes[index]],\n",
    "    #     \"clean_passage\": clean_passages[closest_indexes[index]],\n",
    "    #     \"metadata\": idx_to_metadata[closest_indexes[index]],\n",
    "    #     \"pdf_url\": url,\n",
    "    # }\n",
    "\n",
    "    global idx_to_metadata, idx_to_filename\n",
    "    global english_words\n",
    "    global french_words\n",
    "\n",
    "    if num_answers == None: num_answers = len(answers)\n",
    "\n",
    "    metalist = [(int(idx_to_metadata[idx].split('-')[0]),\n",
    "                 int(idx_to_metadata[idx].split('-')[1])) for idx in answers][:num_answers]\n",
    "    pdflist = list(set(list(map(list, zip(*metalist)))[0]))\n",
    "\n",
    "    textCA = []\n",
    "    for pdf in pdflist:\n",
    "        textCA.append(GV.filterCA(\n",
    "            TEXT_DATA_DIR+idx_to_filename[pdf] + '.pkl', english_words, french_words))\n",
    "\n",
    "    results = []\n",
    "    for meta in metalist:\n",
    "        results.append([idx_to_filename[meta[0]] + '-%i' % meta[1],\n",
    "                        '\\n'.join(textCA[pdflist.index(meta[0])][meta[1]])])\n",
    "\n",
    "\n",
    "    urls = []\n",
    "    for result in results:\n",
    "\n",
    "        #THIS NEEDS TO BE FIXED\n",
    "\n",
    "        filename = result[0].replace(\"texts-pdftotext-fed\",\"texts-pkls\").split(\"texts-pkls\")[1].split(\"-\")[0]\n",
    "        url = \"http://negotech.labour.gc.ca/{}/{}/{}/{}.pdf\"\n",
    "        if filename[-1] == 'a':\n",
    "            url = url.format(\"eng\", \"agreements\",filename[:2], filename)\n",
    "        else:\n",
    "            url = url.format(\"fra\", \"conventions\",filename[:2], filename)\n",
    "\n",
    "        urls.append(url)\n",
    "\n",
    "    answer = [{\"metadata\":result[0].replace(\"texts-pdftotext-fed\",\"texts-pkls\").split(\"texts-pkls\")[1], \"raw_passage\":result[1],\"pdf_url\":urls[index]} for index,result in enumerate(results)]\n",
    "    return(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:14:47.632305Z",
     "start_time": "2017-12-18T15:14:47.626710Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"maternity leave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:15:01.607194Z",
     "start_time": "2017-12-18T15:14:58.083537Z"
    }
   },
   "outputs": [],
   "source": [
    "answer_indexes = retrieve_closest_passages(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:54:00.500885Z",
     "start_time": "2017-12-18T15:54:00.400661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERREUR: pdf(s) introuvable: \n"
     ]
    }
   ],
   "source": [
    "answer_indexes = retrieve_closest_passages(query,from_pdfs=[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:18:28.806977Z",
     "start_time": "2017-12-18T15:18:28.274366Z"
    }
   },
   "outputs": [],
   "source": [
    "answers = get_closest_passages(answer_indexes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "3px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
